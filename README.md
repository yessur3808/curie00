# C.U.R.I.E. - Clever Understanding and Reasoning Intelligent Entity

Curie is an AI assistant that runs **locally** and interacts with users via Telegram.  
It is inspired by conversational assistants like Jarvis from Iron Man, but runs fully on your hardware using state-of-the-art open local language models (no OpenAI account required).

## ğŸŒŸ Features

- **Conversational AI** via Telegram
- **Local LLMs**: Runs Meta Llama 3/3.1 or other GGUF models (no cloud needed)
- **Configurable Persona**: Customizable assistant personality via JSON
- **Memory Management**: Stores conversation history and context
- **Database Integration**: PostgreSQL & MongoDB for data persistence
- **Migration System**: Organized database versioning
- **Utility Scripts**: Helper scripts for common operations
- **Docker Support**: Containerized deployment ready

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Messaging  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Assistant  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Local LLM   â”‚
â”‚ Platforms  â”‚â—€â”€â”€â”€â”€ â”‚ Back-End   â”‚â—€â”€â”€â”€â”€ â”‚ (.gguf, etc)â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚ (Python)   â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚             â”‚             â”‚            â”‚
      â”‚             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
      â”‚                  â”‚                     â”‚
      â–¼                  â–¼                     â–¼
Slack, Telegram,      Memory DB           Local actions
WhatsApp, Voice       (e.g. SQLite,       (filesystem, web,
API                   ChromaDB,           etc)
                      LanceDB)
```



---

## ğŸ“ Project Structure

[Current Directory Structure](./directory_structure.md)


## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- PostgreSQL
- MongoDB
- Docker (optional but preferred)
- `python-telegram-bot` (v20+)
- `llama-cpp-python`
- `python-dotenv`
- At least one GGUF language model (see below)

---

## Setup

### 1. **Clone the repository**
```sh
git clone https://github.com/yessur3808/curie00.git
cd curie00
```


### 2. **Install dependencies**

```sh
pip install -r requirements.txt
```


### 3. **Download a GGUF LLM model**

- Recommended: Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
- Place the .gguf file in the models/ directory.


### 4. **Create a `.env` file in the project root**

```env
TELEGRAM_BOT_TOKEN=your_telegram_token
LLM_MODELS=Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
POSTGRES_URL=postgresql://user:pass@localhost:5432/curie
MONGO_URL=mongodb://localhost:27017/curie
```
You can list multiple GGUF model files (comma-separated) if you want to support switching later.

### 5. Set up databases

```sh
# Apply database migrations
python scripts/apply_migrations.py

# Generate master ID
python scripts/gen_master_id.py

# Insert master user
python scripts/insert_master.py
```

### 6. **Set up your persona (optional)**

Edit assets/persona.json to customize the assistantâ€™s name, greeting, and style.


## Running the Bot

```sh
python main.py
```

or

```sh
python3 main.py
```


Using Docker:

```sh

docker-compose up
```

## ğŸ› ï¸ Development Phases
### Phase 1: Core Functionality âœ…
- [x] Telegram integration
- [x] Local LLM support
- [x] Basic conversation handling


### Phase 2: Memory & Storage âœ…
- [x] PostgreSQL integration
- [x] MongoDB for conversation history
- [x] Migration system


### Phase 3: Enhanced Features ğŸš§
- [ ] Multi-platform support
- [ ] Advanced context management
- [ ] Web interface



## ğŸ“ Notes
- All LLM inference runs locally
- Recommended: 8GB+ RAM for optimal performance
- Supports multiple GGUF models
- Database backups recommended


## ğŸ—ºï¸ Roadmap
- [ ] Voice interface integration
- [ ] WhatsApp connector
- [ ] Discord connector
- [ ] Web dashboard
- [ ] Advanced memory management
- [ ] Multi-user support
- [ ] Plugin system



## ğŸ¤ Contributing
Contributions welcome! Please read our contributing guidelines.

## ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.


---

**Curie: Your Personal AI Assistant, Running Locally!**



